{"cells":[{"cell_type":"markdown","source":["# Explatory analysis - COP26 Tweets during event\n","I applied for a twitter API license and pulled tweets duing the COP26 event relating to COP26 and climate change, to investigate the publics sentiment around the event and what they were most interested in.\n","\n","### What would I like to find out:\n","\n","\n","1.   What are the key themes that people are talking about?\n","2.   What is the overall public sentiment of the event? Can I compare this to twitter / social media benchmark?\n","3. Does sentiment vary over the different themes of discussion?\n","4. Can we see any significant climate denial coming through?\n","\n","5. Named Entity Recognition - Does this actually help?"],"metadata":{"id":"2vaQePGWslhO"}},{"cell_type":"code","execution_count":49,"metadata":{"id":"HJPZTo204Y_z","executionInfo":{"status":"ok","timestamp":1642017373211,"user_tz":0,"elapsed":23691,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["%%capture\n","# Download required packages that are not available already on google colab.\n","!pip install demoji\n","!pip install spacytextblob\n","!python -m spacy download en_core_web_sm \n","!pip install git+https://github.com/rwalk/gsdmm.git\n","!pip install vaderSentiment"]},{"cell_type":"markdown","metadata":{"id":"9m1bUsZEH1w0"},"source":["Model v1 contains climate change\n","Model v2 removes climate change by making it a stop word"]},{"cell_type":"markdown","metadata":{"id":"yL9HoHD7w8hR"},"source":["## Import required libraries\n","If required, run the above code upon opening so that google colab has the required libraries "]},{"cell_type":"code","execution_count":50,"metadata":{"id":"yJFJ0cgQzJjx","executionInfo":{"status":"ok","timestamp":1642017373877,"user_tz":0,"elapsed":672,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Import required libraries\n","\n","# Twitter specific\n","import tweepy\n","\n","# General analysis packages\n","import pandas as pd\n","import numpy as np\n","import json\n","import os\n","import re\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import Counter\n","import pickle\n","\n","# Language Packages\n","import demoji  \n","from string import punctuation\n","import spacy\n","from spacytextblob.spacytextblob import SpacyTextBlob\n","from textblob import TextBlob\n","from gsdmm import MovieGroupProcess\n","from wordcloud import WordCloud\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","# Preload the spacy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","nlp.add_pipe('spacytextblob') # Allows us to use the textblob sentiment analysis tools with spacy\n","# Add any other required stop words\n","nlp.Defaults.stop_words.add(\"cop26\")\n","\n","# Redirect the current python folder to where the Twitter files are located\n","os.chdir(r'/content/drive/MyDrive/Colab Notebooks/Twitter/') # If you map this to where this notebook is saved then gsdmm shoud install in the same location"]},{"cell_type":"markdown","metadata":{"id":"6z2tl_kUxHKp"},"source":["## 0. Load and clean data"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"ww77vGbJp5U5","executionInfo":{"status":"ok","timestamp":1642017373877,"user_tz":0,"elapsed":5,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# # Make sure that Google Drive is mounted before trying to call the below\n","# # Loads my private twitter keys\n","# %run \"Twitter Info.ipynb\""]},{"cell_type":"code","execution_count":52,"metadata":{"id":"YY0HTZCfp5Cp","executionInfo":{"status":"ok","timestamp":1642017373878,"user_tz":0,"elapsed":5,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# # Set up twitter API authentication \n","# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","# auth.set_access_token(access_token, access_secret)\n","# api = tweepy.API(auth)"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"C-0gNGPUeJoD","executionInfo":{"status":"ok","timestamp":1642017427561,"user_tz":0,"elapsed":53687,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Load the combined and partially cleaned dataset\n","tweet_df = pd.read_csv('tweet_df_initial_clean.csv', encoding = 'utf-8', index_col = 0)\n","\n","# My pull out emojis from the tweet data (descriptions)\n","tweet_df['emojis'] = tweet_df['tweets'].apply(lambda x: list(demoji.findall(x).values()))\n","\n","# Flag tweets containing links - these usually refer to another tweet or picture that doesn't provide us any information.\n","def find_link(text):\n","    if 'https' in text:\n","        return True\n","    else: \n","        return False\n","\n","tweet_df['link_check'] = tweet_df['tweets'].apply(lambda x: find_link(x))"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"i2CJhd7kXkDP","executionInfo":{"status":"ok","timestamp":1642017427890,"user_tz":0,"elapsed":344,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Finds mentions in tweets and creates a new column. \n","# Regex expression checks that no @ or letters (or numbers) proceed an @ symbol and then capture to 25 a-Z 0-9 characters afterwards.\n","tweet_df['mentions'] = tweet_df.tweets.str.findall(r'(?<![@\\w])@(\\w{1,25})')"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"zH0UTjrn3prd","executionInfo":{"status":"ok","timestamp":1642017427892,"user_tz":0,"elapsed":19,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Replace emojis with their description in words in a string using demoji function replace_with_desc\n","def replace_emoji(text):\n","    text = replace_with_desc(text, \"\")\n","    return text"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"8gBDlL9uPKI4","executionInfo":{"status":"ok","timestamp":1642017427893,"user_tz":0,"elapsed":20,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove Emojis from text strings - Useful website for finding unicodes of emojis not currently included: https://unicode.org/emoji/charts/full-emoji-list.html#231b\n","def remove_emoji(text):\n","    emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               u\"\\U00002318-\\U0001F566\"  # clocks\n","                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               u\"\\U0001f926-\\U0001f937\"\n","                               u\"\\U00010000-\\U0010ffff\"\n","                               u\"\\u2640-\\u2642\"\n","                               u\"\\u2600-\\u2B55\"\n","                               u\"\\u200d\"\n","                               u\"\\u23cf\"\n","                               u\"\\u23e9\"\n","                               u\"\\u231a\"\n","                               u\"\\ufe0f\"  # dingbats\n","                               u\"\\u3030\"\n","                               \"]+\", flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"SDxuY1I-V4nN","executionInfo":{"status":"ok","timestamp":1642017427893,"user_tz":0,"elapsed":19,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove links from text\n","def remove_links(text):\n","    url_pattern = re.compile(r\"http\\S+\")\n","    return re.sub(url_pattern, '', text)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"sSeIIo-qkzRP","executionInfo":{"status":"ok","timestamp":1642017427894,"user_tz":0,"elapsed":19,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove dates (run before remove punctuation) - Very Basic Version\n","def remove_dates(text):\n","    text = re.sub('\\d+(\\/\\d+)+', '', text) # Removes digits seperated by forward slashes \n","    return text"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1642017427895,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"4LOr8ckRRVSu","outputId":"f2944cdf-7f92-4de0-a600-5046dbe299e0"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'!\"#$%&\\'()*+,-/:;<=>?[\\\\]^_`{|}~'"]},"metadata":{},"execution_count":59}],"source":["# Omit full stops and @ symbols from the punctuation variable (may be useful for other types of analysis)\n","punctuation_edit = punctuation[:13] + punctuation[14:21] + punctuation[22:]\n","punctuation_edit"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"iWtK_eV8O7LO","executionInfo":{"status":"ok","timestamp":1642017427896,"user_tz":0,"elapsed":18,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove all punctuation except for omissions in punctution_edit / punctutation\n","def remove_punc(text):\n","    text = ' '.join(text.split())\n","    text = re.sub('/', ' ', text)\n","    text = (text.encode('ascii', 'ignore')).decode()\n","    text = re.sub(' +', ' ', text)\n","    text = re.sub(r' +\\. +', '. ', text)\n","    text = text.strip()\n","    text = ''.join([char for char in text if char not in punctuation])\n","    #text = ''.join([char for char in text if char not in punctuation_edit]) # Omits '.' & '@'\n","    return text"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"up8dEi5i0HIq","executionInfo":{"status":"ok","timestamp":1642017427897,"user_tz":0,"elapsed":18,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove mentions from text\n","def remove_mention(text):\n","    return re.sub('@\\w+', '', text)"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"5wRjYlnzZOV6","executionInfo":{"status":"ok","timestamp":1642017427898,"user_tz":0,"elapsed":18,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Clean text, calling all the sub-cleaning functions\n","def clean_text(text):\n","    #text = text.lower() - Preprocessing late via SpaCy does the same thing and this makes text more readible until then.\n","    #text = replace_emoji(text)\n","    text = re.sub('&amp;', 'and', text) # Replace &amp: with '&' - encoding error\n","    text = remove_emoji(text)\n","    text = remove_links(text)\n","    text = remove_dates(text)\n","    text = remove_mention(text)\n","    text = remove_punc(text) \n","    return text"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"elapsed":2482,"status":"ok","timestamp":1642017430362,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"1EPYCSfNXYdf","outputId":"590fbccc-c225-4c88-8f31-a780ed5f6de0"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-83cfce78-ff37-45ed-80cc-8f40f102edcb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweets</th>\n","      <th>likes</th>\n","      <th>time</th>\n","      <th>verified</th>\n","      <th>user</th>\n","      <th>hashtags</th>\n","      <th>emojis</th>\n","      <th>link_check</th>\n","      <th>mentions</th>\n","      <th>clean_tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#COP26 has been named the must excluding COP e...</td>\n","      <td>53660</td>\n","      <td>2021-11-04 16:20:40</td>\n","      <td>True</td>\n","      <td>Greta Thunberg</td>\n","      <td>[{'text': 'COP26', 'indices': [0, 6]}]</td>\n","      <td>[]</td>\n","      <td>False</td>\n","      <td>[]</td>\n","      <td>COP26 has been named the must excluding COP ev...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Indonesia reversed a #COP26 pledge to end defo...</td>\n","      <td>5618</td>\n","      <td>2021-11-04 14:31:00</td>\n","      <td>True</td>\n","      <td>AJ+</td>\n","      <td>[{'text': 'COP26', 'indices': [21, 27]}]</td>\n","      <td>[]</td>\n","      <td>True</td>\n","      <td>[]</td>\n","      <td>Indonesia reversed a COP26 pledge to end defor...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sir David Attenborough full speech to World Le...</td>\n","      <td>5227</td>\n","      <td>2021-11-04 10:10:55</td>\n","      <td>True</td>\n","      <td>Chris Packham</td>\n","      <td>[{'text': 'COP26', 'indices': [69, 75]}, {'tex...</td>\n","      <td>[]</td>\n","      <td>True</td>\n","      <td>[]</td>\n","      <td>Sir David Attenborough full speech to World Le...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83cfce78-ff37-45ed-80cc-8f40f102edcb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-83cfce78-ff37-45ed-80cc-8f40f102edcb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83cfce78-ff37-45ed-80cc-8f40f102edcb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              tweets  ...                                        clean_tweet\n","0  #COP26 has been named the must excluding COP e...  ...  COP26 has been named the must excluding COP ev...\n","1  Indonesia reversed a #COP26 pledge to end defo...  ...  Indonesia reversed a COP26 pledge to end defor...\n","2  Sir David Attenborough full speech to World Le...  ...  Sir David Attenborough full speech to World Le...\n","\n","[3 rows x 10 columns]"]},"metadata":{},"execution_count":63}],"source":["# Create a new column based of the cleaning function\n","tweet_df['clean_tweet'] = tweet_df['tweets'].apply(lambda x: clean_text(x))\n","tweet_df.head(3)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"_lkEjONkYgF0","executionInfo":{"status":"ok","timestamp":1642017430363,"user_tz":0,"elapsed":8,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Remove 'to_remove items' from a target list - used to clean the hashtags column read directly from Twitter API\n","# Input: list (target) & str/list containing items to remove, Output: list (target minus the defined items)\n","def remove_all(target_list, to_remove):\n","    if isinstance(to_remove, str): # Remove from a string\n","        for item in target_list:\n","            if item == to_remove:\n","                target_list.remove(to_remove) \n","    \n","    elif isinstance(to_remove, list): # Remove from a list\n","        for rem_item in to_remove:\n","            for item in target_list:\n","                if item == rem_item:\n","                    target_list.remove(rem_item) \n","\n","    return target_list"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"TYhVNN6kZF2O","executionInfo":{"status":"ok","timestamp":1642017430363,"user_tz":0,"elapsed":7,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Take in the hashtags format from twitter, extract the hashtags by finding the text within the entry and remove the words 'text' and 'indices'\n","def fix_hashtags(hashtag_list):\n","    hashtag_string = re.findall(r\"'(.*?)'\", hashtag_list)\n","    hashtag_list_out = remove_all(hashtag_string, ['text', 'indices'])\n","    return hashtag_list_out"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"7RQkRQPYYg36","executionInfo":{"status":"ok","timestamp":1642017431887,"user_tz":0,"elapsed":1531,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Apply fix_hashtags\n","tweet_df['hashtags_clean'] = tweet_df['hashtags'].apply(lambda x: fix_hashtags(x))\n","\n","# Drop old hashtag column and reorder columns\n","tweet_df.drop(columns = ['hashtags'])\n","tweet_df = tweet_df.reindex(columns = ['clean_tweet', 'emojis', 'hashtags_clean', 'mentions', 'likes', 'link_check', 'time', 'verified', 'user', 'tweets'])\n","tweet_df.to_csv('tweet_df.csv', encoding = 'utf-8')"]},{"cell_type":"markdown","metadata":{"id":"S25ScNQ1xMWP"},"source":["## 0.5 Quick analysis of hashtags, emojis and mentions within our dataset"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1642017431888,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"B7ISKq0SZBfE","outputId":"dbc37819-25da-41cc-edaf-1832018b75c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["40708\n","4031\n"]}],"source":["# Look at the number of duplicate tweets\n","print(tweet_df.shape[0])\n","print(tweet_df.clean_tweet.value_counts()[tweet_df.clean_tweet.value_counts() > 1].sum())"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"IZG0ndrbZBZ3","executionInfo":{"status":"ok","timestamp":1642017431889,"user_tz":0,"elapsed":8,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# Drop duplicates, sorting by tweet and then likes\n","def drop_dupes(df):\n","    sorted_df = df.sort_values(by=['clean_tweet', 'likes'])\n","    df_trimmed = df.drop_duplicates(subset=['clean_tweet'])\n","    df_trimmed = df_trimmed.sort_index()\n","    return df_trimmed.reset_index(drop=True)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1642017432195,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"1BpgFsd6l35W","outputId":"956aaabd-22aa-433b-c8c1-8a3d27444521"},"outputs":[{"output_type":"stream","name":"stdout","text":["(40708, 10)\n","(37822, 10)\n"]}],"source":["# Print df shape\n","print(tweet_df.shape)\n","\n","# Drop duplicates and reprint shape\n","tweet_df = drop_dupes(tweet_df)\n","print(tweet_df.shape)"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1642017432195,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"nNTW1VwegEh0","outputId":"77e42814-1dc7-408d-8326-d2e42a630d8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of users in dataset: 27616\n"]},{"output_type":"execute_result","data":{"text/plain":["RSMacKinnon (he/him)    54\n","UNFCCC                  50\n","Top Banana Antiques     47\n","Greta Thunberg News     34\n","Earth Observer          29\n","                        ..\n","Nicole G                 1\n","Bell House               1\n","PNW Collage              1\n","Shilpy Sharma            1\n","Jainish Rathod           1\n","Name: user, Length: 27616, dtype: int64"]},"metadata":{},"execution_count":70}],"source":["# Look at user counts and tweets per user to check that no one user is a major component of our dataset\n","print('Total number of users in dataset:', len(tweet_df.user.unique()))\n","tweet_df.user.value_counts()"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12024,"status":"ok","timestamp":1642017444217,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"y5YPc7m3hnLt","outputId":"a93effa1-13ab-409a-e6f9-de1531a2be9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cop26 : 17983\n","climatechange : 1749\n","climateaction : 1221\n","climatecrisis : 900\n","climate : 872\n","cop26glasgow : 758\n","climateemergency : 647\n","togetherforourplanet : 636\n","netzero : 463\n","climatejustice : 392\n","glasgow : 370\n","sustainability : 320\n","climateactionnow : 288\n","environment : 240\n","uprootthesystem : 236\n","auspol : 220\n","globalwarming : 215\n","klimalaya : 202\n","worldclimatemarch : 185\n","endclimateimperialism : 175\n"]}],"source":["# Create some variables describing the hashtags found in our tweets\n","# None of these look out of place\n","hashtag_list = tweet_df.hashtags_clean.to_list()\n","all_hashtags = [hash.lower() for hashtag in hashtag_list for hash in hashtag] # List of all hashtags (with repetition)\n","unique_hashes = list(set(all_hashtags)) # List of all hashtags (without repitition)\n","hash_counts = dict(zip(unique_hashes, [all_hashtags.count(hash) for hash in unique_hashes])) # Dictionary of hashtag counts\n","hash_counter = Counter(hash_counts)\n","common_hashes = hash_counter.most_common(20)\n","for i in common_hashes:\n","    print(i[0], ':', i[1])"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18476,"status":"ok","timestamp":1642017462679,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"},"user_tz":0},"id":"laX-wSnJ9U30","outputId":"a42dffd2-877c-4835-d6e3-556522dcc574"},"outputs":[{"output_type":"stream","name":"stdout","text":["cop26 : 3583\n","borisjohnson : 1097\n","gretathunberg : 278\n","unfccc : 268\n","aloksharma_rdg : 264\n","youtube : 186\n","un : 167\n","nicolasturgeon : 163\n","cop26_coalition : 153\n","potus : 152\n","unep : 123\n","skynews : 122\n","breezyscroll : 109\n","bbcnews : 102\n","scottmorrisonmp : 99\n","geraldkutney : 98\n","ejwwest : 93\n","veritatem2021 : 87\n","gbnews : 86\n","georgemonbiot : 85\n"]}],"source":["# Create some variables describing the mentions found in our tweets\n","# None of these look out of place - note that Veritatem2021 is an anti climate change account\n","mention_list = tweet_df.mentions.to_list()\n","all_mention = [mention.lower() for mention_sub_list in mention_list for mention in mention_sub_list] # List of all mentions (with repetition)\n","unique_mention = list(set(all_mention)) # List of all mentions (without repitition)\n","mention_counts = dict(zip(unique_mention, [all_mention.count(mention) for mention in unique_mention])) # Dictionary of mention counts\n","mention_counter = Counter(mention_counts)\n","common_mention = mention_counter.most_common(20)\n","for i in common_mention:\n","    print(i[0], ':', i[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFhAmAjDzPpY"},"outputs":[],"source":["# Create some variables describing the emojis found in our tweets\n","# A lot of the emojis seem to be a reference the tweet (i.e index finger pointing right or left) so we may be want to remove them and only add in sentiment where its positive or negative, i.e. smiley faces\n","emoji_list = tweet_df.emojis.to_list()\n","all_emojis = [emojis.lower() for emoji_sub_list in emoji_list for emojis in emoji_sub_list] # List of all emojis (with repetition)\n","unique_emoji = list(set(all_emojis)) # List of all emojis (without repitition)\n","emoji_counts = dict(zip(unique_emoji, [all_emojis.count(emojis) for emojis in unique_emoji])) # Dictionary of emojid counts\n","emoji_counter = Counter(emoji_counts)\n","common_emojis = emoji_counter.most_common(20)\n","for i in common_emojis:\n","    print(i[0], ':', i[1])"]},{"cell_type":"markdown","metadata":{"id":"Rk-_duM6w2QH"},"source":["## 1. Topic Modelling - GDSMM\n","An GDSMM is model which only assumes one topic per document (which is much more likely for short from documents such as Tweets compared to the multi topic assumption required for LDA.\n","* GitHub Repo: https://github.com/rwalk/gsdmm\n","* Full paper here: https://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKovQdnQ1yj8"},"outputs":[],"source":["# Apply spacy preprocessing to the documents in our dataset\n","docs = list(nlp.pipe(tweet_df.clean_tweet))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58Ovigd2bXb-"},"outputs":[],"source":["# Taking a spacy pipeline document, return bool True / False if there is a noun in document\n","def find_noun(spacy_doc):\n","    noun_flag = 0\n","    for token in spacy_doc:\n","        if token.pos_ in ('PROPN', 'PRON', 'NOUN'):\n","            noun_flag = 1\n","            break\n","\n","    if noun_flag == 1:\n","        return(True)\n","    else:\n","        return(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kvvzpEIShum"},"outputs":[],"source":["# Add the tokenized text from our Spacy model to our dataset for use with GSDMM.\n","\n","# Remove stop words in our text\n","docs_tokens = []\n","for doc in docs:\n","    docs_tokens.append([token_iter.lemma_.lower() for token_iter in doc if token_iter.is_stop != True])\n","\n","# Removes the spaces from being added as tokens and also remove single character tokens that may be left in the text as well as stop words\n","docs_tokens2 = []\n","for doc in docs:\n","    docs_tokens2.append([token_iter.lemma_.lower() for token_iter in doc if (token_iter.is_stop != True and token_iter.is_punct != True and len(token_iter.lemma_) > 1)])\n","\n","# Manually remove climate change bigram if sequential in our tokenized text\n","def manual_bigram(input_list):\n","    for index, item in enumerate(input_list):\n","        if index != len(input_list) - 1:\n","            if item == 'climate' and input_list[index + 1] == 'change':\n","                del input_list[index + 1]\n","                del input_list[index]\n","    return input_list\n","\n","# Create a new column with our text ready for modelling\n","tweet_df['prep_tweet'] = docs_tokens2\n","tweet_df['prep_tweet'] = tweet_df['prep_tweet'].apply(lambda x: manual_bigram(x))\n","# Note that removing the phrase 'climate change' has no impact on the sentiment analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrtUh23cxhuZ"},"outputs":[],"source":["# Check our tweets make grammatical sense \n","# Due to the short nature of tweets, sentence structure is hard to code for. Therefore applying a simple check to see if our tweet contains a noun\n","# If it doesn't contain a noun, it is usually referencing an associated tweet or picture which we have no visibility of from the text.\n","noun_check = []\n","for doc in docs:\n","    noun_check.append(find_noun(doc))\n","\n","tweet_df['noun_check'] = noun_check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZAkRbwLZd2z"},"outputs":[],"source":["# Calculate the polarity and subjectivity of each tweet using Spacy's TextBlob pipeline and add to dataset.\n","# Need to revisit to include the sentiment from certain emojis.\n","polarity = []\n","subjectivity = []\n","for doc in docs:\n","    polarity.append(doc._.polarity)\n","    subjectivity.append(doc._.subjectivity)\n","\n","tweet_df['polarity'] = polarity\n","tweet_df['subjectivity'] = subjectivity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YAvwOuWlQES3"},"outputs":[],"source":["# Filter out those tweets that don't have nouns in them\n","df = tweet_df[tweet_df['noun_check'] == True]\n","df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPx6kkqVU-0T"},"outputs":[],"source":["# Look at tweet lengths - note these include the stop words, so length is overstated for modelling purposes\n","print('The shortest tweet is:', df['clean_tweet'].str.len().min())\n","print('The 5% percentile:', df['clean_tweet'].str.len().quantile(q=0.05))\n","print('The mean:', df['clean_tweet'].str.len().quantile(q=0.5))\n","print('The 95th percentile:', df['clean_tweet'].str.len().quantile(q=0.95))\n","print('The longest tweet is:', df['clean_tweet'].str.len().max())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6vUN0BYcZ2Y"},"outputs":[],"source":["# Plot tweet length distribution\n","plt.figure(figsize=(5,8))\n","sns.distplot(df.clean_tweet.str.len())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_N1U1jSYQGC"},"outputs":[],"source":["# Look at shortest tweets. These are mainly aimed directly at people (replies?) or reference other images or tweets.\n","# They contain nouns (hence passed the exclusion) but don't seem to have a pattern I can easily discern around noun type or determiner. \n","\n","df[df['clean_tweet'].str.len() < 42].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmTNNhKtQKLS"},"outputs":[],"source":["# Remove tweets that are too short and unrepresentative of our overall data from our graph\n","df = df[df['clean_tweet'].str.len() > 42]"]},{"cell_type":"markdown","source":["#### GDSMM Model Application / Load\n","Note the model takes a while to run 30-60 mins fresh so the model is saved to a folder called 'models' when run."],"metadata":{"id":"kneP65hp9dzi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8C7UCNRe1yac"},"outputs":[],"source":["# Define the vocab set for our tweets\n","vocab = set(word for sentence in df.prep_tweet for word in sentence)\n","n_terms = len(vocab)"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"zW2ApheGwCS5","executionInfo":{"status":"ok","timestamp":1642017462680,"user_tz":0,"elapsed":23,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"outputs":[],"source":["# # Fit GSDMM model\n","# mgp = MovieGroupProcess(K = 30, alpha = 0.09, beta = 0.11, n_iters = 40)\n","# y = mgp.fit(df.prep_tweet, n_terms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CdKxCIRvP4qf"},"outputs":[],"source":["# # Save GSDMM model\n","# with open(r'models/v2.model', 'wb') as f:\n","#  pickle.dump(mgp, f)\n","#  f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tgfm0qVcMxIG"},"outputs":[],"source":["# Load saved model\n","mgp = pickle.load(open(r'models/v2.model', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nOrFohTwROW"},"outputs":[],"source":["# Function to show the most used words in each of our categories \n","def top_words(mgp, top_clusters, num_words):\n","    for cluster in top_clusters:\n","        sort_dicts = sorted(mgp.cluster_word_distribution[cluster].items(), key = lambda k: k[1], reverse = True)[:num_words]\n","        print ('-'*30)\n","        print('Cluster {}: {}'.format(cluster, sort_dicts))"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KN_OfaRkz1c9","executionInfo":{"status":"ok","timestamp":1642017462680,"user_tz":0,"elapsed":22,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}},"outputId":"89dcfdb8-3767-4130-c189-de0e276389ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of documents per topic: [8334 5511 4127 3649 2880 2703 2456 2159 1989 1211  269   71   64   51\n","   46   35   33   30   29   22   21   20   17   17   16   13   10   10\n","    3    2]\n","Number of documents per topic : [8334 5511 4127 3649 2880 2703 2456 2159 1989 1211  269   71   64   51\n","   46   35   33   30   29   22   21   20   17   17   16   13   10   10\n","    3    2]\n","********************\n","Most important clusters (by number of docs inside): [ 9 28 18 22 23  5 24  6 14 15 26  1 10 13  3]\n","********************\n","------------------------------\n","Cluster 9: [('not', 2158), ('people', 1181), ('climate', 940), ('like', 775), ('think', 695), ('world', 693), ('need', 687), ('change', 681), ('know', 562), ('go', 546)]\n","------------------------------\n","Cluster 28: [('climate', 1752), ('country', 1036), ('coal', 892), ('fossil', 758), ('fuel', 718), ('glasgow', 643), ('agreement', 608), ('deal', 599), ('world', 598), ('draft', 585)]\n","------------------------------\n","Cluster 18: [('climate', 1166), ('need', 587), ('action', 511), ('climatechange', 483), ('nature', 470), ('impact', 438), ('health', 410), ('global', 408), ('world', 391), ('people', 352)]\n","------------------------------\n","Cluster 22: [('climate', 685), ('glasgow', 581), ('today', 484), ('day', 410), ('people', 310), ('action', 302), ('join', 289), ('great', 272), ('world', 271), ('work', 249)]\n","------------------------------\n","Cluster 23: [('energy', 700), ('emission', 374), ('zero', 356), ('transport', 334), ('climate', 323), ('netzero', 317), ('today', 309), ('new', 301), ('carbon', 298), ('day', 297)]\n","------------------------------\n","Cluster 5: [('not', 459), ('johnson', 329), ('boris', 320), ('glasgow', 244), ('world', 198), ('climate', 197), ('uk', 181), ('scotland', 178), ('say', 177), ('like', 170)]\n","------------------------------\n","Cluster 24: [('carbon', 416), ('emission', 332), ('not', 293), ('car', 239), ('reduce', 222), ('need', 215), ('energy', 204), ('fuel', 187), ('help', 169), ('year', 168)]\n","------------------------------\n","Cluster 6: [('join', 633), ('event', 581), ('climate', 536), ('today', 463), ('live', 340), ('register', 246), ('watch', 236), ('glasgow', 229), ('action', 214), ('gmt', 205)]\n","------------------------------\n","Cluster 14: [('climate', 669), ('blah', 303), ('world', 276), ('action', 266), ('leader', 238), ('people', 221), ('uprootthesystem', 218), ('need', 201), ('klimalaya', 201), ('climateaction', 185)]\n","------------------------------\n","Cluster 15: [('year', 154), ('rise', 137), ('sea', 124), ('people', 118), ('climate', 115), ('climatechange', 115), ('level', 100), ('global', 97), ('water', 95), ('weather', 95)]\n","------------------------------\n","Cluster 26: [('diagnose', 72), ('doctor', 51), ('climatecrisis', 50), ('world', 50), ('patient', 49), ('climatechange', 48), ('time4truth', 47), ('woman', 45), ('canadian', 43), ('globalcrisis', 40)]\n","------------------------------\n","Cluster 1: [('banegaswasthindia', 27), ('contest', 25), ('join', 19), ('ans', 18), ('conference', 16), ('2021', 11), ('technology', 11), ('united', 10), ('register', 9), ('itt', 8)]\n","------------------------------\n","Cluster 10: [('conference', 17), ('uae', 17), ('united', 15), ('host', 13), ('cop28', 13), ('nations', 11), ('st', 11), ('2023', 11), ('say', 9), ('win', 8)]\n","------------------------------\n","Cluster 13: [('fab', 43), ('antiquesaregreen', 37), ('christmas', 27), ('antiquejewllery', 21), ('mastercheftheprofessional', 21), ('dogsoftwitter', 7), ('country', 5), ('antiquejewellery', 5), ('gold', 4), ('gardens', 4)]\n","------------------------------\n","Cluster 3: [('palmoil', 14), ('deforestation', 10), ('boycott4wildlife', 9), ('de', 9), ('wallet', 8), ('boycottpalmoil', 7), ('chance', 6), ('continue', 6), ('climate', 5), ('cause', 5)]\n"]}],"source":["# Output the clusters information in a readable format\n","doc_count = np.array(mgp.cluster_doc_count)\n","print('Number of documents per topic: {}'.format(np.sort(doc_count)[::-1]))\n","print('Number of documents per topic :', np.sort(doc_count)[::-1])\n","print('*'*20)\n","# Topics sorted by the number of document they are allocated to\n","top_index = doc_count.argsort()[-15:][::-1]\n","print('Most important clusters (by number of docs inside):', top_index)\n","print('*'*20)\n","# Show the top 10 words in term frequency for each cluster \n","top_words(mgp, top_index, 10)"]},{"cell_type":"markdown","metadata":{"id":"RgEUIwJs7-lY"},"source":["We can see extreme cut off after 10 clusters, lets look at them in more detail."]},{"cell_type":"code","source":["# Define major clusters, so that any other clusters are joined together\n","clusters = top_index[0:10]"],"metadata":{"id":"o1wh7ro8_A0N","executionInfo":{"status":"ok","timestamp":1642017462681,"user_tz":0,"elapsed":19,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","execution_count":43,"metadata":{"id":"DFa3WUrOP4Nu","colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"status":"error","timestamp":1642017308958,"user_tz":0,"elapsed":73739,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}},"outputId":"8c79b741-d032-4ca7-8ad4-448066d18e6f"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-3b16086e9224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-43-3b16086e9224>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-43-3b16086e9224>\u001b[0m in \u001b[0;36mlabel_prob\u001b[0;34m(doc_tokens)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlabel_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_best_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gsdmm/mgp.py\u001b[0m in \u001b[0;36mchoose_best_label\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         '''\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gsdmm/mgp.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_size\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mlD2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlN1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlD1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlN2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlD2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# normalize the probability vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Assign the model classifcations to our data\n","def label_cluster(doc_tokens):\n","    cluster = mgp.choose_best_label(doc_tokens)[0]\n","    if cluster not in clusters:\n","        cluster = 99\n","    return cluster\n","\n","def label_prob(doc_tokens):\n","    probability = mgp.choose_best_label(doc_tokens)[1]\n","    return probability\n","\n","df['cluster'] = df.prep_tweet.apply(lambda x: label_cluster(x))\n","df['probability'] = df.prep_tweet.apply(lambda x: label_prob(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdS87nbo9A8e"},"outputs":[],"source":["# Plot cluster probabilities \n","plt.figure(figsize=(5,8))\n","sns.distplot(df.probability, bins = 100)\n","plt.xlim(0.6,1)"]},{"cell_type":"markdown","metadata":{"id":"pIi1kdQiBXbU"},"source":["The probabilities output by the model are very high (a very small number of entries are left off the graph to the left)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSd187Zq9A5w"},"outputs":[],"source":["clusters = np.append(cluster, 99)\n","\n","plt.figure(figsize = (20,25))\n","\n","wc = WordCloud(stopwords = nlp.Defaults.stop_words, background_color=\"white\", colormap=\"Dark2\", max_words = 100,\n","               max_font_size=75, collocations = True, random_state=42)\n","\n","# Create subplots for each cluster\n","count = 0\n","for cluster in clusters:\n","    wc.generate(' '.join(df[df['cluster'] == cluster].clean_tweet))\n","    plt.subplot(6, 2, count + 1)\n","    plt.imshow(wc, interpolation=\"bilinear\")\n","    plt.axis(\"off\")\n","    plt.title('Cluster ' + str(cluster))\n","    count +=1\n","    \n","plt.show()"]},{"cell_type":"markdown","source":["Looking at these clusters we can some clear topics have been found within our dataset (99 is an amalgamation of the other categories) - this is my interpretation of each topic so far:\n","- 9 - General climate change vocabulary\n","- 28 - Fossil fuels and emissions agreements\n","- 18 - Call to action for health / nature / planet\n","- 22 - Event specific (days, timings, glasgow)\n","- 23 - Net zero \n","- 5 - Politics around the event (Glasgow, Boris, private jets etc)\n","- 24 - Waste / Emissions and calls for alternatives\n","- 6 - Event specific (days, timings, glasgow\n","- 14 - Hashtags from COP\n","- 15 - Effect of Climate Change on Earth (Drought, carbon water etc)\n","- 99 - \n","\n","\n"],"metadata":{"id":"6WB65NgASZST"}},{"cell_type":"markdown","source":["## 2. Overall Sentiment"],"metadata":{"id":"a9N6tGzpATI1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlcprxsUam0r"},"outputs":[],"source":["# Plot the sentiment scores of all of our tweets.\n","# Can clearly see a triangular shape, which showing that the more factual a tweet is, the more likely it is to be neutral\n","plt.figure(figsize = (15,8))\n","plt.scatter(df['polarity'], df['subjectivity'])\n","plt.axhline(y = df['subjectivity'].mean(), color='r', linestyle='-')\n","plt.axvline(x = df['polarity'].mean(), color='r', linestyle='-')\n","plt.title('Sentiment Analysis', fontsize=20)\n","plt.xlabel('<-- Negative -------- Positive -->', fontsize=15)\n","plt.ylabel('<-- Facts -------- Opinions -->', fontsize=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZvZ1suK8N26"},"outputs":[],"source":["plt.figure(figsize = (20,25))\n","# Create subplots for each cluster - Red is the original sentiment on the dataset and black is the sentiment for that specific cluster\n","count = 0\n","for cluster in top_index[0:10]:\n","    temp_df = df[df['cluster'] == cluster]\n","    plt.subplot(5, 2, count + 1)\n","    plt.scatter(temp_df['polarity'], temp_df['subjectivity'])\n","    plt.title('Cluster ' + str(cluster))\n","    plt.ylim(-0.02,1.02)\n","    plt.xlim(-1.02,1.02)\n","    plt.axhline(y = temp_df['subjectivity'].mean(), color='k', linestyle='-')\n","    plt.axvline(x = temp_df['polarity'].mean(), color='k', linestyle='-')\n","    plt.axhline(y = df['subjectivity'].mean(), color='r', linestyle='-')\n","    plt.axvline(x = df['polarity'].mean(), color='r', linestyle='-')\n","    count += 1\n","plt.show()"]},{"cell_type":"markdown","source":["We can see in these graphs the sentiment for each individual cluster. The red axis show the average sentiment over the entire dataset while the black axis show the sentiment for the specific cluster displayed. There seems to be more variance in sentiment than in subjectivity for the clusters.\n","\n","Interesting call outs are: \n","- For all clusters with a positively shifted polarity, we lose the classic V shape we had in our original graph, and we see the positive half of our graph (/). However we don't see the reverse for the charts with a negatively shifted polarity.\n","- The larges positive shifts were seen in the event specific tweet clusters, along with call the action clusters about planetary health and net zero (note these are more focused in the future).\n","- Negative polatiry shifts were seen for the fossil fuel and effects of climate change clusters (along with the political cluster).\n"],"metadata":{"id":"pdetDKrjbgqx"}},{"cell_type":"code","source":["df['temp_emojis'] = [' '.join(map(str, item)) for item in df['emojis']]\n","df['temp_clean_tweet'] = df['clean_tweet'] + ' ' + df['temp_emojis']"],"metadata":{"id":"878ZKp0qk-l5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['vs_polarity'] = df.temp_clean_tweet.apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x)['compound'])"],"metadata":{"id":"uDyz7LEX9xwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.vs_polarity.max())\n","print(df.vs_polarity.min())"],"metadata":{"id":"-gBsb-i2CaAd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.histplot(data = df, x = 'vs_polarity')"],"metadata":{"id":"xibNJepKCC32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["names = top_index[0:10]\n","fig, axes = plt.subplots(5,2, figsize=(20,25))\n","fig.tight_layout(pad = 4)\n","count = 0\n","for name, ax in zip(names, axes.flatten()):\n","    temp_df = df[df['cluster'] == name]\n","    ax.set_title('Cluster ' + str(name))\n","    sns.histplot(data = temp_df, x = 'vs_polarity', ax=ax)\n","    count += 1"],"metadata":{"id":"aMDnzNhqXkcv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["These charts give us similar overall sentiment distributions to the previous charts using textblob."],"metadata":{"id":"NeRBUMVPq_QN"}},{"cell_type":"code","source":["# Polarity differences between the two polarity methods\n","df['pol_diff'] = df['vs_polarity'] - df['polarity']\n","\n","# Look at tweet lengths - note these include the stop words, so length is overstated for modelling purposes\n","print('The largest negative shift is:', df['pol_diff'].min())\n","print('The 5% percentile:', df['pol_diff'].quantile(q=0.05))\n","print('The mean shift:', df['pol_diff'].quantile(q=0.5))\n","print('The 95th percentile:', df['pol_diff'].quantile(q=0.95))\n","print('The largets postive shift is:', df['pol_diff'].max())\n","\n","# Plot tweet length distribution\n","plt.figure(figsize=(8,8))\n","sns.distplot(df.pol_diff)\n"],"metadata":{"id":"AoHmmpg6r4-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"6MdJjKyqr48B","executionInfo":{"status":"aborted","timestamp":1642017308964,"user_tz":0,"elapsed":7,"user":{"displayName":"Matthew Pritchard","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11617894563761551826"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Twitter API v2.ipynb","provenance":[{"file_id":"1nh6vgfg57aB0pgSHigM5X_xr4dDBZZcr","timestamp":1641552160414}],"mount_file_id":"17o7gbcVoIBfSmxsGK1gMu0coo3P8_Vwn","authorship_tag":"ABX9TyMtAoMJwNymfesgbL/aaoNu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}